{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8cc4fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import logging\n",
    "import os\n",
    "import logging\n",
    "import requests\n",
    "\n",
    "schema_text = \"\"\"\n",
    "Table: users (id, name, email)\n",
    "Table: orders (id, user_id, amount, date)\n",
    "Table: products (id, name, price)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ed914e-d49f-476e-9b86-4691a2e68fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e96dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_chunk_lines(text, chunk_size=3):\n",
    "    lines = text.strip().split('\\n')\n",
    "    chunks = []\n",
    "    for i in range(0, len(lines), chunk_size):\n",
    "        chunk = '\\n'.join(lines[i:i+chunk_size]).strip()\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "    return chunks\n",
    "#WITH OVERLAP\n",
    "# def chunk_with_overlap(text, chunk_size=3, overlap=1):\n",
    "#     lines = text.strip().split('\\n')\n",
    "#     chunks = []\n",
    "    \n",
    "#     step = chunk_size - overlap  # Jump size is reduced to allow overlap\n",
    "    \n",
    "#     for i in range(0, len(lines), step):\n",
    "#         chunk = '\\n'.join(lines[i:i + chunk_size]).strip()\n",
    "#         if chunk:\n",
    "#             chunks.append(chunk)\n",
    "            \n",
    "#     return chunks\n",
    "\n",
    "\n",
    "chunks = simple_chunk_lines(schema_text, chunk_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45f13ed5-93ed-4f3e-bc30-129851337335",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_embedding(text):\n",
    "    OLLAMA_URL = \"http://localhost:11434\"\n",
    "    EMBED_MODEL = \"mxbai-embed-large\"\n",
    "    url = f\"{OLLAMA_URL}/api/embeddings\"\n",
    "    payload = {\"model\": EMBED_MODEL, \"prompt\": text}\n",
    "\n",
    "    response = requests.post(url, json=payload)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    return response.json()[\"embedding\"]\n",
    "\n",
    "embeddings = [get_embedding(chunk) for chunk in chunks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "316a2094-8a95-44ca-93cd-7109501b03b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "# # Connect to Chroma (new style)\n",
    "# client = chromadb.PersistentClient(path=\"chroma_db\")\n",
    "\n",
    "# # Create or get collection\n",
    "# collection = client.get_or_create_collection(name=\"sql_docs\")\n",
    "\n",
    "# # Suppose you have:\n",
    "# # - chunks (already created)\n",
    "# # - embeddings (you just generated)\n",
    "\n",
    "# ids = [f\"chunk_{i}\" for i in range(len(chunks))]\n",
    "# print(ids)\n",
    "# collection.add(\n",
    "#     documents=chunks,\n",
    "#     embeddings=embeddings,\n",
    "#     ids=ids\n",
    "# )\n",
    "\n",
    "# print(\"Embeddings successfully stored in ChromaDB!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f1377ea-e9df-497c-9399-ffe285882fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def StoreEmbeddingsInVec_db(embeddings, chunks):\n",
    "    client = chromadb.PersistentClient(path=\"newchroma_db\")\n",
    "    collection = client.get_or_create_collection(name=\"sql_docs\")\n",
    "    ids = [f\"chunk_{i}\" for i in range(len(chunks))]\n",
    "    \n",
    "    collection.add(\n",
    "    documents=chunks,\n",
    "    embeddings=embeddings,\n",
    "    ids=ids\n",
    "    )\n",
    "    print(\"Embeddings successfully stored in ChromaDB!\")\n",
    "    return collection\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2092f33-fee7-4cab-a1c2-8d1a32ae09f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_question = \"What is there\"\n",
    "\n",
    "# # Step 1: Get embedding for the question\n",
    "# query_embedding = get_embedding(user_question)\n",
    "\n",
    "# # Step 2: Query ChromaDB\n",
    "# results = collection.query(\n",
    "#     query_embeddings=[query_embedding],\n",
    "#     n_results=3  # Top 3 most similar chunks\n",
    "# )\n",
    "\n",
    "# relevant_chunks = results['documents'][0]  # It's a list of lists\n",
    "\n",
    "# # Combine them into a context\n",
    "# context = \"\\n\".join(relevant_chunks)\n",
    "\n",
    "# print(\"Retrieved context:\\n\", context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3d9db33-c74b-4946-8fe4-27504a2c0f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieveContext(collection):\n",
    "    userQuestion = \"What is there\"\n",
    "    # Step 1: Get embedding for the question\n",
    "    query_embedding = get_embedding(userQuestion)\n",
    "\n",
    "# Step 2: Query ChromaDB\n",
    "    results = collection.query(\n",
    "    query_embeddings=[query_embedding],\n",
    "    n_results=3  # Top 3 most similar chunks\n",
    "    )\n",
    "\n",
    "    relevant_chunks = results['documents'][0]  # It's a list of lists\n",
    "\n",
    "# Combine them into a context\n",
    "    context = \"\\n\".join(relevant_chunks)\n",
    "\n",
    "    return context\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9f8fc7a-d411-4256-b301-67c1407b0a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# promptt = f\"\"\"\n",
    "# You are an SQL expert. Based on the following schema and data chunks:\n",
    "# {context}\n",
    "\n",
    "# Answer the question:\n",
    "# {user_question}\n",
    "# \"\"\"\n",
    "def makePrompt(context, userQuestion):\n",
    "    promptt = f\"\"\"\n",
    "    You are an SQL expert. Based on the following schema and data chunks:\n",
    "    {context}\n",
    "\n",
    "    Answer the question:\n",
    "    {userQuestion}\n",
    "    \"\"\"\n",
    "    return promptt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4550b6b0-d154-45f7-935c-61d354274fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "def ask_gemma(prompt):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    payload = {\"model\": \"gemma3:1b\", \"prompt\": prompt}\n",
    "\n",
    "    response = requests.post(url, json=payload)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    answer = \"\"\n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            data = line.decode('utf-8')\n",
    "            json_obj = json.loads(data)   # Or use json.loads(data) if you're sure it's clean JSON\n",
    "            if 'response' in json_obj:\n",
    "                answer += json_obj['response']\n",
    "\n",
    "    return answer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d4109b-b881-423e-bf24-2823b3150f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "195f0169-b5c3-4b7c-aa0d-507dca3892c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Retrieve(text):\n",
    "    chunks = simple_chunk_lines(text, chunk_size=1)\n",
    "    embeddings = [get_embedding(chunk) for chunk in chunks]\n",
    "    coll =StoreEmbeddingsInVec_db(embeddings, chunks)\n",
    "    context = retrieveContext(coll)\n",
    "    return context\n",
    "    # prompt = makePrompt(context, query)\n",
    "    # answer = ask_gemma(prompt)\n",
    "    # return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ae27af0-3d37-470b-bd3b-b248aa2842c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QueryLLM(question, context):\n",
    "    prompt = makePrompt(context, question)\n",
    "    answer = ask_gemma(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8556a3a6-717b-4f57-aac0-ca71ca0238fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings successfully stored in ChromaDB!\n"
     ]
    }
   ],
   "source": [
    "context= Retrieve(schema_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2eecd625-ce10-4d23-af2f-aa0d8c7ee1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's tackle this. You've provided a simple schema with a few tables representing products, users, and orders.  The question \"Hey, how are you?\" is a completely unrelated and nonsensical prompt. \n",
      "\n",
      "**My Response:**\n",
      "\n",
      "As an SQL expert, I understand you've asked me a question that doesn't fit within the context of SQL.  My purpose is to help with data manipulation and analysis.  Since youâ€™ve given me the table schema, I can offer some assistance if you need it.\n",
      "\n",
      "**To help me answer your question effectively, could you please clarify *what* you're trying to achieve?**\n",
      "\n",
      "For example, are you:\n",
      "\n",
      "*   **Trying to write a query?** If so, what are you trying to accomplish? (e.g., \"Give me all products with a price over $100\")\n",
      "*   **Looking for information about the tables?** (e.g., \"Show me the columns in the `products` table\")\n",
      "*   **Need help with a specific task using SQL?** (e.g., \"I need to join the `users` and `orders` tables to find orders placed by a specific user\")\n",
      "\n",
      "\n",
      "**I'm here to help you with SQL. Just let me know what you're looking for.**\n",
      "\n",
      "I'm ready when you are.\n"
     ]
    }
   ],
   "source": [
    "answer = QueryLLM(\"Hey, how youre doing?\", context)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09797cb3-493a-45fc-b1c2-9f0a6d606c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
